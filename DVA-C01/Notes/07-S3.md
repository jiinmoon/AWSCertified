# Simple Storage Service

## S3 Buckets and Objects

- The files (objects) are stored in S3 buckets.
- Buckets require a globally unique name.
- It is **Region** scoped.
- Each object has a key that is a full path to the object:
    - s3://samplebucket/samplefile.txt
    - s3L//samplebucket/samplefolder/sampleimage.jpg
- Each key is composed of prefix and object name.
    - samplefolder/ is the prefix
    - sampleimage.jpg is the object name

- Note that there really are no directories; it is just a way to organize
  files.

- Max objecy size is 5 TB; must use multi-part upload if larger than 5 GB but
  recommended for any file over 100 MB.

- It may also contain metadata and tags.

## S3 Versioning

- Versioning is enabled at the bucket level.
- Same key will increment the version.
- Versioning is to protect against accidental deletes and rollbacks.
- Note that files prior to the versioning will be version "null".
- Suspending versioning does not delete the versions.

## S3 Encrytion for Objects

- 4 Methods:
    - SSE-S3 : encryts objects using keys handled by S3.
    - SSE-KMS : leverages KMS to manage the encrytion keys.
    - SSE-C : provide own encrytion keys.
    - Client-Side Encrytion.

### SSE-S3

- Server-side encryption using AES-256.
- Data Encryton Key is handled by AWS S3.
- Set header to `"x-amz-server-side-encryption":"AES256"`.

### SSE-KMS

- Server-side encrytion using KMS key (CMK).
- Provides user control and audit trail via KMS.
- Set header to `"x-amz-server-side-encryption":"aws:kms"`.

### SSE-C

- Server-side encryption using data keys provided by customer.
- S3 does not store the keys.
- **HTTPS is required**.
- Encryption key must be included in the header for every request made.

### Client-Side Encryption

- Client manades its own keys and encryption.
- S3 won't even realize that the data is encrypted.

## Encrytion in Transit

- S3 exposes both HTTP and HTTPS endpoints.
- HTTPS is recommened over HTTP (with exception of SSE-C where it is
  mandatory).

## S3 Security

- User based:
    - IAM Policies - controls who can call which S3 APIs.

- Resource based:
    - Bucket Policies - bucket-level rules from the S3 console (allow for cross
      account controsl as well).
    - Object Access Control List - per object control.
    - Bucket Access Control List - not commonly used.

- General Rule: **an IAM principal can access an object iff the user IAM
  permission or the resource policy ALLOW and there is no explicit DENY**.
    - DENY over ALLOW.

### S3 Bucket Policies

- It is a JSON based policies which following parameters:
    - Resources : buckets or objects (ARN).
    - Actions : API to perform (i.e. s3:GetObject).
    - Effect : Allow or Deny.
    - Principal : account or user to apply this rule (i.e. \*).

- S3 bucket policy is used to
    - grant public access to the bucket.
    - force objects to be encrytped at upload (deny PutObject API calls that
      does not have a matching encrytpion header).
    - grant access to another account for cross-account access.

### Bucket settings for Blocking Public Access

- Block public access to buckets anre objects granted through:
    - new access control lists
    - any access control lists
    - new public bucket or access point policies

- Block public and cross-account access to buckets and objects through any
  public bucket or access point policies.

### S3 Extra Security

- Supports VPC Endpoints.
- S3 access logs can be stored in other S3 bucket; S3 API calls can be logged
  to CloudTrail.
- MFA Delete can be set-up with **versioned** buckets so that it can prevent
  deletion of objects.
- Pre-Signed URLs with TTL can be generated to provide temporary access to the
  users.

## S3 Static Websites

- S3 hosts a static websites that can be accessed over internet.
- URL will be `bucket-name.s3-website-aws-region.amazonaws.com`.
- If 403 error, change the bucket policy that allows for public reads!

## S3 CORS

- Cross-Origin Region Sharing.
- Origin is (scheme, host, port).
    - i.e. `https://example.com` (HTTPS protocol at example.com using port
      443).
- It is a web browser based mechanism to allow request to other origins that
  are referenced from one origin.

- i.e. static website hosted on S3 may reference an image that is stored in
  another bucket.

- If main domain name is same, then it is considered same origin:
    - `https://example.com/file1` == `https://example.com/file2`.
- If sub-domain name is different, then it is considered different origin:
    - `https://abc.example.com/` != `https://xyz.example.com/`.

- These requests will be rejected unless the other refered origin allows for
  the requests using CORS Headers (`Access-Control-Allow-Origin`).

- Web browser when it encounters CORS object to get, it will first send the
  preflight request to the cross-origin.

- Preflight response will send back headers and allow methods; and web browser
  can perform http method operations to cross origin.

- If a client does a cross-origin request on S3 bucket, we need to enable the
  correct CORS headers.
- You can either allow for a specific origin or for "*" all origins.

## S3 COnsistency Model

- Read after write consistency for PUTS of new objects.
    - meaning, GET after WRITE of **new** objects will always return the
      latest.

- Eventual Consistency for DELETES and PUTS of existing objects.
    - even after deleting the object, it maybe is possible to still access it
      for a short duration after.

- We cannot force strong consistency with S3.


